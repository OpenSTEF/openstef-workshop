{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d655a5c0",
   "metadata": {},
   "source": [
    "# Workshop part 2 | Learn how to make a forecast\n",
    "In this second part of the workshop, we will use the model trained in the first part and make a forecast with it. \n",
    "\n",
    "Note: if you were not able to train the model in the first part, we have trained one for you. It is in this folder: ``mlflow_trained_model``. It will follow in this tutorial how to use this. \n",
    "\n",
    "The learning points are:\n",
    "- Hands on experience with using a trained model; \n",
    "- What data is required to make a forecast;\n",
    "- Hands on experience using forecast pipeline;\n",
    "- How the model gets automatically loaded;\n",
    "- How the predictions compare to the measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ebc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages.\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import openstef\n",
    "from openstef.pipeline.create_forecast import create_forecast_pipeline\n",
    "from openstef.data_classes.prediction_job import PredictionJobDataClass\n",
    "\n",
    "# Set plotly as the default pandas plotting backend.\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b59cfa0",
   "metadata": {},
   "source": [
    "## Define the prediction job\n",
    "The same as in workshop part 1, a prediction job has to be defined. As we are making a forecast for the model we trained in part 1, we can use the exact same prediction job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define properties of training/prediction. We call this a 'prediction_job'. The same is used as in the first exercise.\n",
    "pj = dict(id=287,\n",
    "        model='xgb', \n",
    "        quantiles=[0.10,0.30,0.50,0.70,0.90],\n",
    "        forecast_type=\"demand\", \n",
    "        lat=52.0,\n",
    "        lon=5.0,\n",
    "        horizon_minutes=2880,\n",
    "        resolution_minutes=15,\n",
    "        name=\"workshop_exercise_2\",\n",
    "        save_train_forecasts=True,\n",
    "       )\n",
    "\n",
    "pj=PredictionJobDataClass(**pj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20a4ee",
   "metadata": {},
   "source": [
    "## Prepare the input data\n",
    "Some other preparation of the input data is required for making a forecast. Namely, split into a test and train data set. \n",
    "\n",
    "Exercise: \n",
    "- Split the data into a train and test data set. Where the train dataset contains everything except the final 192 rows, and the test dataset contains this final 192 rows;\n",
    "\n",
    "Hint: you can look at this [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=pd.read_csv(\"../data/input_data_sun_heavy.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "train_data= ...# Everything except the final 192 rows for training.\n",
    "test_data= ...# Final 192 rows for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4018dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_data)==192, \"test data is of invalid length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098adf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data to make the forecast.\n",
    "realised=input_data.loc[test_data.index, 'load'].copy(deep=True)\n",
    "to_forecast_data=input_data.copy(deep=True)\n",
    "to_forecast_data.loc[test_data.index, 'load']= np.nan # Clear the load data for the part you want to forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c23b5",
   "metadata": {},
   "source": [
    "## Make the prediction\n",
    "Now that the prediction job has been defined, a model has been trained and the input data is prepared, a forecast can be made. \n",
    "\n",
    "Exercise: \n",
    "- Using the prediction job, trained model and to_forecast_data, make a forecasting with the OpenSTEF pipeline;\n",
    "- How long did it take to make a forecast?\n",
    "\n",
    "Hint: look-up the correct pipeline on the OpenSTEF [website](https://openstef.github.io/openstef/user_guides.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51264dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location where the model was stored in the last exercise.\n",
    "mlflow_tracking_uri=r\"./mlflow_trained_models\" \n",
    "\n",
    "forecast=openstef.pipeline. ... (\n",
    "    ...,\n",
    "    ..., \n",
    "    mlflow_tracking_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba5c1ad",
   "metadata": {},
   "source": [
    "# Inspect the results\n",
    "Now that the forecast has been made, the results can be analysed. \n",
    "\n",
    "Exercise: answer the following questions \n",
    "- Look at the results, when is the model accurate and when is it less accurate? Why?\n",
    "- Look at the two weather features plotted, do you see correlation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(forecast.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53931a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_forecast_realised=pd.concat([forecast[\"forecast\"], realised], axis=1).plot()\n",
    "fig_forecast_realised.update_layout(\n",
    "    xaxis_title='Timestamp',\n",
    "    yaxis_title=\"Load [MW]\"\n",
    ")\n",
    "fig_forecast_realised.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ce716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the normalized plots of both the radiation and forecast, do you recognize any paterns?\n",
    "\n",
    "fig_forecast_radiation=pd.concat(\n",
    "    [\n",
    "        test_data[\"radiation\"]/max(test_data[\"radiation\"]),\n",
    "        forecast[\"forecast\"]/max(forecast[\"forecast\"])\n",
    "    ], axis=1).plot()\n",
    "fig_forecast_radiation.update_layout(\n",
    "    xaxis_title='Timestamp',\n",
    "    yaxis_title=\"Normalized values\"\n",
    ")\n",
    "display(fig_forecast_radiation.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_forecast_windspeed=pd.concat(\n",
    "    [\n",
    "        test_data[\"windspeed\"]/max(test_data[\"windspeed\"]),\n",
    "        forecast[\"forecast\"]/max(forecast[\"forecast\"])\n",
    "    ], axis=1).plot()\n",
    "fig_forecast_windspeed.update_layout(\n",
    "    xaxis_title='Timestamp',\n",
    "    yaxis_title=\"Normalized values\"\n",
    ")\n",
    "display(fig_forecast_windspeed.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725334f1",
   "metadata": {},
   "source": [
    "## Alter the input data \n",
    "In the code below, the radiation input data is divided by ten and thereafter a forecast is made with this new input data. Thus, with the same prediction job and trained model, a forecast is made using ten percent the 'sunshine' as input. \n",
    "\n",
    "Exercise: answer the following question: \n",
    "- What happens to the forecast when the radiation is divided by ten? Why? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee359bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the radiation data by ten.\n",
    "to_forecast_data_rad=to_forecast_data.copy()\n",
    "to_forecast_data_rad['radiation']=0.1*(to_forecast_data['radiation'])\n",
    "\n",
    "# Make a forecast with this new input data.\n",
    "mlflow_tracking_uri=r\"./mlflow_trained_models\" \n",
    "\n",
    "forecast_rad=create_forecast_pipeline(\n",
    "    pj,\n",
    "    to_forecast_data_rad, \n",
    "    mlflow_tracking_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd14545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the results.\n",
    "radiation_forecast_comparison = pd.DataFrame(\n",
    "    test_data[\"radiation\"]/max(test_data[\"radiation\"])\n",
    ")\n",
    "\n",
    "radiation_forecast_comparison[\"forecast_full_radiation\"] = forecast[\"forecast\"]/max(forecast[\"forecast\"])\n",
    "radiation_forecast_comparison[\"forecast_little_radiation\"] = forecast_rad[\"forecast\"]/max(forecast_rad[\"forecast\"])\n",
    "\n",
    "\n",
    "fig_radiation_forecast_comparison=radiation_forecast_comparison.plot()\n",
    "\n",
    "fig_radiation_forecast_comparison.update_layout(\n",
    "    xaxis_title='Timestamp',\n",
    "    yaxis_title=\"Normalized values\"\n",
    ")\n",
    "display(fig_radiation_forecast_comparison.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcab1fa",
   "metadata": {},
   "source": [
    "## Bonus: Dashboard\n",
    "Did you know that OpenSTEF has an eloborate dashboard which shows you everything you want to know about your forecast? Check it the dashboard documentation [here](https://raw.githack.com/OpenSTEF/.github/main/profile/html/openstef_dashboard_doc.html) . \n",
    "\n",
    "Which different in- and output components do you see in this dashboard? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
