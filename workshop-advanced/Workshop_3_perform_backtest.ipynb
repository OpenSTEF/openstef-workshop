{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d655a5c0",
   "metadata": {},
   "source": [
    "# Workshop part 3 | Learn how to perform a backtest\n",
    "In the third part of this workshop, we will perform a backtest for the same location as the first two parts.\n",
    "\n",
    "The learning points are:\n",
    "- What a backtest is and how it works on a high level;\n",
    "- Hands on experience with evaluating a model using a backtest;\n",
    "- Being able to understand the results of a backtest.\n",
    "\n",
    "A backtest is the evaluation of the model on historical data. Essentially, it is a way of testing how OpenSTEF would have performed if it had been used in the past. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d727ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import openstef\n",
    "from openstef.data_classes.model_specifications import ModelSpecificationDataClass\n",
    "from openstef.data_classes.prediction_job import PredictionJobDataClass \n",
    "from openstef.pipeline.train_create_forecast_backtest import train_model_and_forecast_back_test\n",
    "\n",
    "# Set plotly as the default pandas plotting backend\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61766752",
   "metadata": {},
   "source": [
    "## Define the prediction job\n",
    "The same as in workshop parts 1 and 2, a prediction job has to be defined. As we are making a backttest for same location, we can use the exact same prediction job. \n",
    "\n",
    "You can find the documentation [here](https://github.com/OpenSTEF/openstef/blob/main/openstef/data_classes/prediction_job.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define properties of training/prediction. We call this a 'prediction_job'. The same is used as in the first exercise.\n",
    "pj = dict(id=287,\n",
    "        model='xgb', \n",
    "        quantiles=[0.10,0.30,0.50,0.70,0.90],\n",
    "        forecast_type=\"demand\", \n",
    "        lat=52.0,\n",
    "        lon=5.0,\n",
    "        horizon_minutes=2880,\n",
    "        resolution_minutes=15,\n",
    "        name=\"workshop_exercise_2\",\n",
    "        save_train_forecasts=True,\n",
    "       )\n",
    "\n",
    "pj=PredictionJobDataClass(**pj)\n",
    "modelspecs = ModelSpecificationDataClass(id=pj['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf006f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=pd.read_csv(\"../data/input_data_sun_heavy.csv\", index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c23b5",
   "metadata": {},
   "source": [
    "## Perform the backtest\n",
    "The prediction job and input data have been provided above, so now a backtest can be performed. \n",
    "\n",
    "Exercise: \n",
    "- Train a model and make a backtest uing one OpenSTEF pipeline \n",
    "\n",
    "    - Hint 1: find the correct pipeline on the OpenSTEF [website](https://openstef.github.io/openstef/user_guides.html);\n",
    "\n",
    "    - Hint 2: You only need 1 pipeline to train the model and make a forecast!\n",
    "\n",
    "\n",
    "Note: The training_horizons is the horizon of the desired forecast in minutes. It entails how far into the future we want to predict. The value of 0.25 entails that at the moment of prediction, you predict 15 minutes into the future. So let's say you make a prediction at one o'clock, than the prediction is for 13.15 o'clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51264dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=1\n",
    "\n",
    "forecast, model, train_data, validation_data, test_data = openstef.pipeline. ... (\n",
    "    ...,\n",
    "    modelspecs = modelspecs,\n",
    "    input_data = ...,\n",
    "    training_horizons=[0.25, 47.0],\n",
    "    n_folds=n_folds,\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd4c95",
   "metadata": {},
   "source": [
    "## Evaluate the results \n",
    "Below, the results from the backtest are plotted. With these plots, answer the question on the exercise below. \n",
    "\n",
    "Exercise: answer the following questions: \n",
    "- When is the model uncertain? Why? \n",
    "- What differences do you see between the horizons? \n",
    "- Look at the differences between the forecast and realized? What do you see? Why? \n",
    "\n",
    "Bonus: look at the differences between the two time horizons using metrics. You can use the build-in metrics package of OpenSTEF. Find a suitable metric and implement this in the code. See the documentation website [here](https://openstef.github.io/openstef/openstef.metrics.html).Does the difference in metrics confirm your answers given above?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for horizon in set(forecast.horizon):\n",
    "    fig = forecast.loc[forecast.horizon==horizon,['quantile_P10','quantile_P30',\n",
    "                    'quantile_P50','quantile_P70','quantile_P90','realised','forecast']].plot(\n",
    "                                                                                   title=f\"Horizon: {horizon}\")\n",
    "    fig.update_traces(\n",
    "         line=dict(color=\"green\", width=1), fill='tonexty', fillcolor='rgba(0, 255, 0, 0.1)',\n",
    "         selector=lambda x: 'quantile' in x.name and x.name != 'quantile_P10')\n",
    "    fig.update_traces(\n",
    "         line=dict(color=\"green\", width=1),\n",
    "         selector=lambda x: 'quantile_P10' == x.name)\n",
    "    fig.update_traces(\n",
    "         line=dict(color=\"red\", width=2),\n",
    "         selector=lambda x: 'realised' in x.name)\n",
    "    fig.update_traces(\n",
    "         line=dict(color=\"blue\", width=2),\n",
    "         selector=lambda x: 'forecast' in x.name)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "for horizon in set(forecast.horizon):\n",
    "     score=openstef. ...  (forecast.loc[forecast.horizon==horizon, 'realised'], forecast.loc[forecast.horizon==horizon, 'forecast'])\n",
    "     print(horizon, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa13a5",
   "metadata": {},
   "source": [
    "## Bonus: Use linear model\n",
    "OpenSTEF is not hardcoded to use a specific model. In contrary: OpenSTEF can be used with basically any model with relatively low implementation effort!\n",
    "This is important, because depending on the situation and goals you want to achieve with your forecast, you might want to use a different type of model that is good at a specific thing.\n",
    "For example, XGBoost is good at learning complex relations and predicting a forecast that overall follow the measurements quite closely. However, XGBoost is not so good at predicting extreme peaks, especially if the peak was not present in the training data. A simpler model like linear quantile regression should be able to predict those peaks better. Luckily, it is already implemented in OpenSTEF!\n",
    "\n",
    "Re-run the code from notebook 1 and 2, but this time with the `linear_quantile` model in the prediction job. What differences do you see? As we are currently using a full year of data to train, and the current implementation of this model type is quite slow, we recommend you reduce the training data to around 3 months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c56969",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
